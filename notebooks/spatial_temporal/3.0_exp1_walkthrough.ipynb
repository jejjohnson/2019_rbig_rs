{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial-Temporal Experiment\n",
    "\n",
    "In this notebook, I will be walking through how we can estimate different methods based on the density cubes that we derive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "root = here(project_files=[\".here\"])\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "import pathlib\n",
    "\n",
    "# standard python packages\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xcube.core.geom import clip_dataset_by_geometry\n",
    "\n",
    "# \n",
    "from src.features import Metrics\n",
    "from src.features.preprocessing import DensityCubes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # esdc tools\n",
    "# from src.esdc.subset import select_pixel\n",
    "# from src.esdc.shape import ShapeFileExtract, rasterize\n",
    "# from esdc.transform import DensityCubes\n",
    "\n",
    "from typing import List, Dict\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# NUMPY SETTINGS\n",
    "import numpy as onp\n",
    "onp.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# MATPLOTLIB Settings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# SEABORN SETTINGS\n",
    "import seaborn as sns\n",
    "sns.set_context(context='talk',font_scale=0.7)\n",
    "# sns.set(rc={'figure.figsize': (12, 9.)})\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# PANDAS SETTINGS\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# LOGGING SETTINGS\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    stream=sys.stdout,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "#logger.setLevel(logging.INFO)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Union, Tuple\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import shapely\n",
    "# global variables\n",
    "\n",
    "# Datapath\n",
    "DATA_PATH = pathlib.Path(\"/media/disk/databases/ESDC/\")\n",
    "\n",
    "levels = ['time', 'lon', 'lat']\n",
    "\n",
    "# get filename\n",
    "filename = DATA_PATH.joinpath(\"esdc-8d-0.25deg-1x720x1440-2.0.0.zarr\")\n",
    "\n",
    "Region = namedtuple(\"Region\", [\"name\", \"lonmin\", \"lonmax\", \"latmin\", \"latmax\"])\n",
    "TimePeriod = namedtuple(\"TimePeriod\", [\"name\", \"start\", \"end\"])\n",
    "\n",
    "def get_test_time() -> TimePeriod:\n",
    "    return TimePeriod(name=\"201001_201012\", start=\"Jan-2010\", end=\"Dec-2010\")\n",
    "#     return TimePeriod(name='test_201007', start='July-2010', end='July-2010')\n",
    "\n",
    "def get_europe() -> Region:\n",
    "    \"\"\"As an example, I often choose Europe. This is a decent bounding box.\"\"\"\n",
    "    return Region(name=\"europe\", latmax=35.5, latmin=71.5, lonmax=60.0, lonmin=-18.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'gross_primary_productivity',\n",
    "    'root_moisture',\n",
    "    'land_surface_temperature'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, Flow, Parameter\n",
    "\n",
    "@task # get Dataset\n",
    "def get_dataset(variable: str)-> xr.Dataset:\n",
    "    return xr.open_zarr(str(filename))[[variable]]\n",
    "\n",
    "@task # subset datacube\n",
    "def cube_spatial_subset(xr_data: xr.Dataset, bbox: Region) -> xr.Dataset:\n",
    "    \"\"\"Function to spatially subset an xarray dataset from a bounding box.\"\"\"\n",
    "    # get bounding box\n",
    "    bbox = shapely.geometry.box(\n",
    "        bbox.lonmin,\n",
    "        bbox.latmin,\n",
    "        bbox.lonmax,\n",
    "        bbox.latmax\n",
    "    )\n",
    "    # subset datacube\n",
    "    return clip_dataset_by_geometry(xr_data, bbox)\n",
    "\n",
    "@task \n",
    "def cube_temporal_subset(xr_data: xr.DataArray, period: Tuple[str, str]) -> xr.DataArray:\n",
    "    \"\"\"Function to temporally subset an xarray dataset from a tuple of\n",
    "    start date and end date\n",
    "    \"\"\"\n",
    "    return xr_data.sel(time=slice(period.start, period.end))\n",
    "\n",
    "@task # get reference cube\n",
    "def get_reference_cube(data: xr.DataArray) -> pd.DataFrame:\n",
    "    \"\"\"Wrapper Function to get reference cube\"\"\"\n",
    "    return data.to_dataframe().dropna().reorder_levels(levels)\n",
    "\n",
    "@task # get density cubes\n",
    "def get_density_cubes(data: xr.DataArray, spatial: int, temporal: int) -> pd.DataFrame:\n",
    "    \"\"\"Wrapper Function to get density cubes from a dataarray\"\"\"\n",
    "    return DensityCubes(\n",
    "        spatial_window=spatial,\n",
    "        time_window=temporal\n",
    "    ).get_minicubes(data).reorder_levels(levels)\n",
    "    \n",
    "@task # get common indices\n",
    "def get_common_indices(\n",
    "    reference_df: pd.DataFrame, density_df: pd.DataFrame\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    idx = density_df.index.intersection(reference_df.index)\n",
    "    return reference_df.loc[idx,:], density_df.loc[idx, :]\n",
    "\n",
    "@task # standardize the data before\n",
    "def standardizer_data(X: pd.DataFrame, Y: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    # standardizer\n",
    "    normalizer = StandardScaler(with_mean=True, with_std=True)\n",
    "    \n",
    "    # standardize X values\n",
    "    X_values = normalizer.fit_transform(X.values)\n",
    "    X = pd.DataFrame(data=X_values, index=X.index, columns=X.columns)\n",
    "    \n",
    "    # standardize Y Values\n",
    "    Y_values = normalizer.fit_transform(Y.values)\n",
    "    Y = pd.DataFrame(data=Y_values, index=Y.index, columns=Y.columns)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "@task\n",
    "def get_similarity_scores(X_ref: pd.DataFrame, Y_compare: pd.DataFrame) -> Dict:\n",
    "    \n",
    "    # RV Coefficient\n",
    "    rv_results = rv_coefficient(X_ref, Y_compare)\n",
    "    \n",
    "#     # CKA Coefficient\n",
    "#     cka_results = cka_coefficient(X_ref, Y_compare)\n",
    "    \n",
    "    # RBIG Coefficient\n",
    "    rbig_results = rbig_it_measures(X_ref, Y_compare)\n",
    "    \n",
    "    results = {\n",
    "        **rv_results,\n",
    "#         **cka_results,\n",
    "        **rbig_results\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.similarity import cka_coefficient, rv_coefficient, rbig_it_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable = 'gross_primary_productivity'\n",
    "# region = get_europe()\n",
    "\n",
    "# datacube = get_dataset(variable)\n",
    "\n",
    "# datacube = subset_cube(xr_data=datacube, bbox=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "with Flow(\"Experiment-Step\") as flow:\n",
    "    \n",
    "    # ======================\n",
    "    # experiment parameters\n",
    "    # ======================\n",
    "    variable = Parameter(\"variable\", default='gross_primary_productivity')\n",
    "    region = Parameter(\"region\", default=get_europe())\n",
    "    period = Parameter(\"period\", default=get_test_time())\n",
    "    spatial = Parameter(\"spatial\", default=1)\n",
    "    temporal = Parameter(\"temporal\", default=3)\n",
    "    \n",
    "    # ======================\n",
    "    # experiment - Data\n",
    "    # ======================\n",
    "    # Get DataCube\n",
    "    datacube = get_dataset(variable)\n",
    "    \n",
    "    # subset datacube (spatially)\n",
    "    datacube = cube_spatial_subset(xr_data=datacube, bbox=region)[variable]\n",
    "\n",
    "    # subset datacube (temporally)\n",
    "    datacube = cube_temporal_subset(xr_data=datacube, period=period)\n",
    "    \n",
    "    # get datacubes\n",
    "    reference_cube_df = get_reference_cube(data=datacube)\n",
    "    \n",
    "    # get density cubes\n",
    "    density_cube_df = get_density_cubes(\n",
    "        data=datacube, \n",
    "        spatial=spatial, \n",
    "        temporal=temporal\n",
    "    )\n",
    "    \n",
    "    # get reference dataframe\n",
    "    dfs = get_common_indices(\n",
    "        reference_df=reference_cube_df, \n",
    "        density_df=density_cube_df\n",
    "    )\n",
    "    \n",
    "    # standardize data\n",
    "    dfs = standardizer_data(X=dfs[0], Y=dfs[1])\n",
    "    \n",
    "    # ======================\n",
    "    # experiment - Methods\n",
    "    # ======================\n",
    "    res = get_similarity_scores(X_ref=dfs[0], Y_compare=dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-05-01 10:16:21] INFO - prefect.FlowRunner | Beginning Flow run for 'Experiment-Step'\n",
      "2020-05-01 12:16:21,361:INFO:Beginning Flow run for 'Experiment-Step'\n",
      "[2020-05-01 10:16:21] INFO - prefect.FlowRunner | Starting flow run.\n",
      "2020-05-01 12:16:21,372:INFO:Starting flow run.\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'variable': Starting task run...\n",
      "2020-05-01 12:16:21,411:INFO:Task 'variable': Starting task run...\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'variable': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:21,424:INFO:Task 'variable': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'region': Starting task run...\n",
      "2020-05-01 12:16:21,454:INFO:Task 'region': Starting task run...\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'region': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:21,467:INFO:Task 'region': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'period': Starting task run...\n",
      "2020-05-01 12:16:21,496:INFO:Task 'period': Starting task run...\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'period': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:21,509:INFO:Task 'period': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'temporal': Starting task run...\n",
      "2020-05-01 12:16:21,539:INFO:Task 'temporal': Starting task run...\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'temporal': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:21,551:INFO:Task 'temporal': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:21] INFO - prefect.TaskRunner | Task 'get_dataset': Starting task run...\n",
      "2020-05-01 12:16:21,581:INFO:Task 'get_dataset': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_dataset': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,485:INFO:Task 'get_dataset': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'cube_spatial_subset': Starting task run...\n",
      "2020-05-01 12:16:22,505:INFO:Task 'cube_spatial_subset': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'cube_spatial_subset': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,525:INFO:Task 'cube_spatial_subset': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'GetItem': Starting task run...\n",
      "2020-05-01 12:16:22,545:INFO:Task 'GetItem': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,554:INFO:Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'cube_temporal_subset': Starting task run...\n",
      "2020-05-01 12:16:22,574:INFO:Task 'cube_temporal_subset': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'cube_temporal_subset': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,585:INFO:Task 'cube_temporal_subset': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_reference_cube': Starting task run...\n",
      "2020-05-01 12:16:22,605:INFO:Task 'get_reference_cube': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_reference_cube': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,653:INFO:Task 'get_reference_cube': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'spatial': Starting task run...\n",
      "2020-05-01 12:16:22,687:INFO:Task 'spatial': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'spatial': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,700:INFO:Task 'spatial': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_density_cubes': Starting task run...\n",
      "2020-05-01 12:16:22,729:INFO:Task 'get_density_cubes': Starting task run...\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_density_cubes': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:22,769:INFO:Task 'get_density_cubes': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:22] INFO - prefect.TaskRunner | Task 'get_common_indices': Starting task run...\n",
      "2020-05-01 12:16:22,799:INFO:Task 'get_common_indices': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'get_common_indices': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,766:INFO:Task 'get_common_indices': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': Starting task run...\n",
      "2020-05-01 12:16:23,786:INFO:Task 'GetItem': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,795:INFO:Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': Starting task run...\n",
      "2020-05-01 12:16:23,815:INFO:Task 'GetItem': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,824:INFO:Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'standardizer_data': Starting task run...\n",
      "2020-05-01 12:16:23,843:INFO:Task 'standardizer_data': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'standardizer_data': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,855:INFO:Task 'standardizer_data': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': Starting task run...\n",
      "2020-05-01 12:16:23,874:INFO:Task 'GetItem': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,883:INFO:Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': Starting task run...\n",
      "2020-05-01 12:16:23,903:INFO:Task 'GetItem': Starting task run...\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:23,912:INFO:Task 'GetItem': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:23] INFO - prefect.TaskRunner | Task 'get_similarity_scores': Starting task run...\n",
      "2020-05-01 12:16:23,931:INFO:Task 'get_similarity_scores': Starting task run...\n",
      "[2020-05-01 10:16:50] INFO - prefect.TaskRunner | Task 'get_similarity_scores': finished task run for task with final state: 'Success'\n",
      "2020-05-01 12:16:50,094:INFO:Task 'get_similarity_scores': finished task run for task with final state: 'Success'\n",
      "[2020-05-01 10:16:50] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "2020-05-01 12:16:50,097:INFO:Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "state = flow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rv_coeff': 0.9697258,\n",
       " 'rv_x_norm': 26692.072,\n",
       " 'rv_y_norm': 77907.49,\n",
       " 'rv_xy_norm': 2016556900.0,\n",
       " 'rbig_H_x': 1.855240533094599,\n",
       " 'rbig_H_y': 1.1286197933913034,\n",
       " 'rbig_I_xy': 5.499353957238775,\n",
       " 'rbig_vi_coeff': 3.8004736863738287}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.result[res].result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rbig_eo]",
   "language": "python",
   "name": "conda-env-.conda-rbig_eo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
